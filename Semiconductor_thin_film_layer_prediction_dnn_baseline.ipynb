{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devyulbae/AIClass/blob/main/Semiconductor_thin_film_layer_prediction_dnn_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THNjjG50BYJY"
      },
      "source": [
        "# 반도체 박막 두께 분석\n",
        "\n",
        "### 배경\n",
        "\n",
        "최근 고사양 반도체 수요가 많아지면서 반도체를 수직으로 적층하는 3차원 공정이 많이 연구되고 있습니다. 반도체 박막을 수십 ~ 수백 층 쌓아 올리는 공정에서는 박막의 결함으로 인한 두께와 균일도가 저하되는 문제가 있습니다. 이는 소자 구조의 변형을 야기하며 성능 하락의 주요 요인이 됩니다. 이를 사전에 방지하기 위해서는 박막의 두께를 빠르면서도 정확히 측정하는 것이 중요합니다.\n",
        "\n",
        "박막의 두께를 측정하기 위해 광스펙트럼 분석이 널리 사용되고 있습니다. 하지만 광 스펙트럼을 분석하기 위해서는 관련 지식을 많이 가진 전문가가 필요하며 분석과정에 많은 컴퓨팅자원이 필요합니다. 빅데이터 분석을 통해 이를 해결하고자 반도체 소자의 두께 분석 알고리즘 경진대회를 개최합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XN-kkqUGNko"
      },
      "source": [
        "### 배경 자료\n",
        "\n",
        "반도체 박막은 얇은 반도체 막으로 박막의 종류와 두께는 반도체 소자의 특성을 결정짓는 중요한 요소 중 하나입니다. 박막의 두께를 측정하는 방법으로 반사율 측정이 널리 사용되며 반사율은 입사광 세기에 대한 반사광 세기의 비율로 정해집니다. (반사율 = 반사광/입사광) 반사율은 빛의 파장에 따라 변하며 파장에 따른 반사율의 분포를 반사율 스펙트럼이라고 합니다.\n",
        "\n",
        "\n",
        "\n",
        "### 구조 설명\n",
        "\n",
        "이번 대회에서 분석할 소자는 질화규소(layer_1)/이산화규소(layer_2)/질화규소(layer_3)/이산화규소(layer_4)/규소(기판) 총 5층 구조로 되어 있습니다. 대회의 목적은 기판인 규소를 제외한 layer_1 ~ layer_4의 두께를 예측하는 것으로 학습 데이터 파일에는 각 층의 두께와 반사율 스펙트럼이 포함되어 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "### 데이터 설명\n",
        "\n",
        "train.csv 파일에는 4층 박막의 두께와 파장에 따른 반사율 스펙트럼이 주어집니다. 헤더의 이름에 따라 layer_1 ~ 4는 해당 박막의 두께,\n",
        "\n",
        "데이터값인 0 ~ 225은 빛의 파장에 해당하는 반사율이 됩니다. 헤더 이름인 0~225은 파장을 뜻하며 비식별화 처리가 되어있어 실제 값과는 다릅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHebfq47CZ-V"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATOrWJKuLlBT"
      },
      "source": [
        "use_colab = True\n",
        "assert use_colab in [True, False]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFNOIeSn_Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57effe01-bf98-4e99-ac6d-c5d34da6416e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qoXy0bqBqKt"
      },
      "source": [
        "### 데이터 로드\n",
        "* 새로운 버전의 Colab파일에선 왼쪽의 폴더 tree에서 직접 드라이브 마운트를 진행해야합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwp9HSrrD4XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9997fc82-15ab-40a1-dee1-4e945d90d002"
      },
      "source": [
        "train_d = np.load(\"/content/drive/MyDrive/datas/semicon_train_data.npy\")\n",
        "test_d = np.load(\"/content/drive/MyDrive/datas/semicon_test_data.npy\")\n",
        "\n",
        "# train data path\n",
        "# train_d = np.load(\"./semicon_train_data.npy\")\n",
        "\n",
        "# test data path\n",
        "# train_d = np.load(\"./semicon_test_data.npy\")\n",
        "print(train_d.shape, test_d.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(729000, 230) (81000, 230)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHTnjvhZi4x9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184c17ba-d22d-477e-8b94-a1a587f8052d"
      },
      "source": [
        "print(train_d[1].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(230,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsF_kurljuwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fbc6ac-feb8-49ec-e2c5-338910919b7a"
      },
      "source": [
        "print(test_d[0].shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(230,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdXgDw8oyTQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5c89a9-ecba-41d3-e4e2-5830ac3749f1"
      },
      "source": [
        "# Raw Data 확인\n",
        "print(train_d[1000])\n",
        "# print(test_d[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.00000000e+01 4.00000000e+01 1.50000000e+02 1.10000000e+02\n",
            " 4.02068880e-01 4.05173400e-01 4.22107550e-01 4.35197980e-01\n",
            " 4.66261860e-01 4.67785980e-01 4.76300870e-01 5.07203700e-01\n",
            " 5.23296600e-01 5.31541170e-01 5.23319200e-01 5.32340650e-01\n",
            " 5.38513840e-01 5.62478700e-01 5.74338900e-01 5.62083540e-01\n",
            " 5.83467800e-01 5.88462350e-01 5.89606940e-01 5.93186560e-01\n",
            " 5.93241930e-01 5.98241150e-01 5.87171000e-01 5.92055500e-01\n",
            " 6.06527860e-01 5.87087870e-01 5.94492100e-01 5.73233500e-01\n",
            " 5.94926300e-01 5.76777600e-01 5.70286300e-01 5.76913000e-01\n",
            " 5.52754400e-01 5.61735150e-01 5.52500000e-01 5.23800200e-01\n",
            " 5.11056840e-01 5.11732600e-01 4.92525460e-01 4.73373200e-01\n",
            " 4.57444160e-01 4.53428800e-01 4.19270130e-01 3.87709920e-01\n",
            " 3.87221520e-01 3.49848450e-01 3.16229370e-01 3.13858700e-01\n",
            " 2.80085700e-01 2.61263000e-01 2.30250820e-01 1.98457850e-01\n",
            " 1.53500440e-01 1.36026740e-01 1.08726785e-01 8.95344000e-02\n",
            " 6.58975300e-02 5.09539300e-02 3.69604570e-02 2.88708470e-02\n",
            " 1.54857090e-02 1.99594010e-02 2.33170990e-02 3.26487760e-02\n",
            " 5.89796340e-02 6.33707600e-02 9.20634640e-02 1.24182590e-01\n",
            " 1.63985540e-01 1.81501220e-01 2.16830660e-01 2.57668080e-01\n",
            " 2.86428720e-01 3.21613600e-01 3.65077380e-01 3.85984180e-01\n",
            " 4.33254400e-01 4.36655340e-01 4.60312520e-01 4.99771740e-01\n",
            " 5.03849100e-01 5.48682200e-01 5.58029060e-01 5.62947630e-01\n",
            " 5.99234340e-01 5.96399550e-01 6.04513000e-01 6.19093400e-01\n",
            " 6.38402700e-01 6.64816900e-01 6.56996000e-01 6.66098600e-01\n",
            " 6.69130500e-01 6.70661600e-01 6.80202360e-01 6.92821600e-01\n",
            " 6.96852400e-01 7.02015160e-01 7.00507460e-01 7.00250800e-01\n",
            " 7.11669300e-01 6.96838260e-01 7.08974360e-01 7.19114100e-01\n",
            " 7.18034700e-01 7.00589540e-01 7.05873250e-01 6.92893500e-01\n",
            " 7.14911160e-01 6.85250640e-01 6.82136830e-01 6.81311400e-01\n",
            " 6.78019200e-01 6.67259900e-01 6.78185700e-01 6.52875660e-01\n",
            " 6.34932940e-01 6.36031400e-01 6.16502100e-01 5.91461400e-01\n",
            " 5.74673350e-01 5.57246200e-01 5.42328200e-01 5.19422200e-01\n",
            " 5.03134850e-01 4.81939820e-01 4.45872100e-01 4.17206170e-01\n",
            " 4.05306970e-01 3.55970500e-01 3.27808440e-01 2.89738060e-01\n",
            " 2.44837760e-01 2.16494500e-01 1.69062380e-01 1.23260050e-01\n",
            " 1.03297760e-01 6.77379500e-02 3.89807700e-02 2.52380610e-02\n",
            " 2.59922780e-02 1.38827340e-02 1.90851740e-02 6.68724550e-02\n",
            " 7.21453900e-02 1.14929430e-01 1.77696590e-01 2.11153720e-01\n",
            " 2.55038900e-01 2.95599580e-01 3.21243700e-01 3.74151170e-01\n",
            " 3.91486200e-01 4.27665320e-01 4.61769700e-01 4.75576340e-01\n",
            " 4.78055980e-01 5.16503040e-01 5.30934450e-01 5.23902500e-01\n",
            " 5.51259300e-01 5.65235300e-01 5.67701600e-01 5.70858800e-01\n",
            " 5.76418300e-01 5.75021860e-01 6.01967200e-01 5.79546750e-01\n",
            " 5.81157900e-01 5.93576100e-01 5.84070600e-01 6.04394850e-01\n",
            " 5.87139800e-01 5.93731460e-01 5.91678200e-01 5.63344300e-01\n",
            " 5.69886800e-01 5.46404960e-01 5.43537260e-01 5.42394760e-01\n",
            " 5.42762940e-01 5.26218060e-01 4.89471520e-01 4.72608000e-01\n",
            " 4.59845570e-01 4.39476280e-01 4.24489440e-01 4.16756120e-01\n",
            " 4.11724180e-01 3.81418440e-01 3.60050380e-01 3.37973600e-01\n",
            " 3.20442830e-01 2.97488420e-01 2.85940900e-01 2.82688900e-01\n",
            " 2.78886770e-01 2.60735480e-01 2.64526520e-01 2.38374640e-01\n",
            " 2.46523140e-01 2.54422630e-01 2.63443470e-01 2.77559100e-01\n",
            " 3.05792480e-01 3.04755750e-01 3.47745950e-01 3.42683080e-01\n",
            " 3.59969050e-01 3.90264000e-01 4.21746500e-01 4.33448700e-01\n",
            " 4.50429620e-01 4.94950400e-01 4.90516330e-01 5.15429500e-01\n",
            " 5.46570300e-01 5.64438460e-01 5.68110800e-01 5.71491600e-01\n",
            " 5.81447660e-01 5.84012000e-01 6.05881900e-01 5.98874870e-01\n",
            " 5.97313170e-01 5.95610300e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJTUCIIAt01D"
      },
      "source": [
        "* 데이터를 분석하여 모델에 학습할 수 있는 형태로 정리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awmkQxq8sWsG"
      },
      "source": [
        "train = train_d[:,4:] # 729000, 230 15번째 데이터부터 가져온다.\n",
        "label = train_d[:,:4]\n",
        "\n",
        "t_train = test_d[:,4:] # 81000, 230개 14번째 까지 데이터를 가져온다.\n",
        "t_label = test_d[:,:4]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Cb4BQPKqVs"
      },
      "source": [
        "batch_size =64\n",
        "\n",
        "# for train\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train, label))\n",
        "train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=batch_size, drop_remainder=True)\n",
        "\n",
        "# for test\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((t_train, t_label))\n",
        "test_dataset = test_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
        "print(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsJ2qMl3Bryb"
      },
      "source": [
        "### 모델 구성\n",
        "* 현재 가장 간단한 모델로 구성되어 있습니다.\n",
        "* 데이터셋 자체를 가장 잘 학습할 수 있는 모델을 구현해 학습을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "8 * 8 * 4"
      ],
      "metadata": {
        "id": "aCo8AxpUS5kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzo9y_5eryuq"
      },
      "source": [
        "def leaky_relu(x, alpha=0.01):\n",
        "    return tf.maximum(x, alpha * x)\n",
        "\n",
        "input_tensor = layers.Input(shape=([226,]))\n",
        "\n",
        "x_base = layers.Dense(8*8, activation='relu')(input_tensor) # 64\n",
        "\n",
        "\n",
        "x1 = layers.Reshape(target_shape=([4, 16]))(x_base) # 256x1 -> 4x64\n",
        "x1 = layers.Conv1D(16, 1, activation='relu')(x1) # 1x64\n",
        "x1 = layers.Reshape(target_shape=([64, 1]))(x1) # 1x64 -> 256x1\n",
        "\n",
        "x2 = layers.Reshape(target_shape=([8, 8, 1]))(x_base)  # 8x8x1\n",
        "x2 = layers.Conv2D(4, 4, strides=2, padding='same', activation=lambda x: leaky_relu(x))(x2) # 4x4x8\n",
        "x2 = layers.Reshape(target_shape=([64, 1]))(x2) # 4x4x8 -> 64x1\n",
        "\n",
        "x3 = layers.Reshape(target_shape=([64, 1]))(x_base) # 256x1\n",
        "x3 = layers.GRU(units=64, return_sequences=False, recurrent_initializer='glorot_uniform')(x3) # 256x1\n",
        "# no need to reshape RNN shape\n",
        "\n",
        "x_sum = layers.Add()([x1, x2, x3]) # 64x64\n",
        "\n",
        "x_sum = layers.Reshape(target_shape=([32, 32, 4]))(x_sum)  # 128x128x4\n",
        "x_sum = layers.Conv2D(16, 8, strides=2, activation=lambda x: leaky_relu(x))(x_sum) # 16x16x16\n",
        "x_sum = layers.Conv2D(16, 4, strides=2, padding='same', activation=lambda x: leaky_relu(x))(x_sum) # 8x8x16\n",
        "x_sum = layers.Conv2D(32, 4, strides=2, padding='same', activation=lambda x: leaky_relu(x))(x_sum) # 8x8x32\n",
        "\n",
        "x_sum = layers.Flatten()(x_sum)\n",
        "output_tensor = layers.Dense(4)(x_sum)\n",
        "\n",
        "model = tf.keras.Model(input_tensor, output_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "K1ckgdad9u4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0OODMx4Btb5"
      },
      "source": [
        "### 모델 학습\n",
        "* 4개층의 박막의 두께를 예측하는 모델을 학습해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlhAzzfCLDQ0"
      },
      "source": [
        "# the save point\n",
        "if use_colab:\n",
        "    checkpoint_dir ='./drive/My Drive/train_ckpt/semiconductor/exp1'\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "else:\n",
        "    checkpoint_dir = 'semiconductor/exp1'\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor='val_loss',\n",
        "                                                 mode='auto',\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaTHvzqjuCQS"
      },
      "source": [
        "model.compile(loss='mae', #mse\n",
        "              optimizer='adam',\n",
        "              metrics=['mae']) #mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUUO_VcoLJEg"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    steps_per_epoch=len(train) / batch_size, # train data의 길이 // batch 길이\n",
        "                    epochs=100,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=len(t_train) / batch_size,\n",
        "                    callbacks=[early_stopping, cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcx7cdQgLWau"
      },
      "source": [
        "# np.save(\"file/path.npy\", history.numpy())\n",
        "# history = np.load(\"histoy.npy\", allow_pickle=True)\n",
        "\n",
        "loss=history.history['mae'] # mse\n",
        "val_loss=history.history['val_mae'] # val_mse\n",
        "\n",
        "epochs_range = range(len(loss))\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(epochs_range, loss, label='Training MAE') # MSE\n",
        "plt.plot(epochs_range, val_loss, label='Validation MAE') # MSE\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation MAE') # MSE\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIPmAVP1u9nX"
      },
      "source": [
        "### 모델 평가\n",
        "* Mean absolute error 를 이용해 모델이 정확히 예측하는지를 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqsdquFJuKUv"
      },
      "source": [
        "# model.load_weights(checkpoint_dir)\n",
        "results = model.evaluate(test_dataset)\n",
        "print(\"MAE :\", results[0]) # MAE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}