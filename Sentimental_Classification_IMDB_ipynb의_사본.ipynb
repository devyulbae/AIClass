{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "553px",
        "left": "792px",
        "right": "61px",
        "top": "71px",
        "width": "375px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devyulbae/AIClass/blob/main/Sentimental_Classification_IMDB_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oq4UnWajC9u"
      },
      "source": [
        "# Sentiment Classification\n",
        "\n",
        "### Task\n",
        "* IMDB 영화사이트에서 50000개의 영화평을 가지고 positive/negative인지 구분해보자.\n",
        "* 데이터 불러오기를 제외한 딥러닝 트레이닝 과정을 직접 구현해보는 것이 목표 입니다.\n",
        "\n",
        "### Dataset\n",
        "* [IMDB datasets](https://www.imdb.com/interfaces/)\n",
        "\n",
        "### Base code\n",
        "* Dataset: train, val, test로 split\n",
        "* Input data shape: (`batch_size`, `max_sequence_length`)\n",
        "* Output data shape: (`batch_size`, 1)\n",
        "* Architecture:\n",
        "  * RNN을 이용한 간단한 classification 모델 가이드\n",
        "  * `Embedding` - `SimpleRNN` - `Dense (with Sigmoid)`\n",
        "  * [`tf.keras.layers`](https://www.tensorflow.org/api_docs/python/tf/keras/layers) 사용\n",
        "* Training\n",
        "  * `model.fit` 사용\n",
        "* Evaluation\n",
        "  * `model.evaluate` 사용 for test dataset\n",
        "\n",
        "### Try some techniques\n",
        "* Training-epochs 조절\n",
        "* Change model architectures (Custom model)\n",
        "  * Use another cells (LSTM, GRU, etc.)\n",
        "  * Use dropout layers\n",
        "* Embedding size 조절\n",
        "  * 또는 one-hot vector로 학습\n",
        "* Number of words in the vocabulary 변화\n",
        "* `pad` 옵션 변화\n",
        "* Data augmentation (if possible)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKq6mIljjC9v"
      },
      "source": [
        "## 자연어처리에 관한 work flow\n",
        "\n",
        "The flowchart of the algorithm is roughly:\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/11681225/46912373-d2a3a800-cfae-11e8-8201-ef17b65834f5.png\" alt=\"natural_language_flowchart\" style=\"width: 300px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW9rRFr4jC9w"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbt0_EpOvL6C"
      },
      "source": [
        "use_colab = True\n",
        "assert use_colab in [True, False]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibO_zjJmvN3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fd4d31-5f16-4ab5-ef21-9290e8b945a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:42.026345Z",
          "start_time": "2019-03-04T06:05:40.302942Z"
        },
        "id": "ct7ZVZ2EjC9x"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e3ucn5_jC90"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "* IMDB에서 다운받은 총 50000개의 영화평을 사용한다.\n",
        "* `tf.keras.datasets`에 이미 잘 가공된 데이터 셋이 있으므로 쉽게 다운받아 사용할 수 있다.\n",
        "* 원래는 text 데이터이지만 `tf.keras.datasets.imdb`는 이미 Tokenizing이 되어있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:42.083083Z",
          "start_time": "2019-03-04T06:05:42.075925Z"
        },
        "id": "DKOg8JCsjC91"
      },
      "source": [
        "# Load training and eval data from tf.keras\n",
        "imdb = tf.keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "train_labels = train_labels.astype(np.float64)\n",
        "test_labels = test_labels.astype(np.float64)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:48.627470Z",
          "start_time": "2019-03-04T06:05:48.619679Z"
        },
        "id": "7mL9LbzXjC96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c638adff-3175-42ad-f579-6d3e1140c9a2"
      },
      "source": [
        "print(\"Train-set size: \", len(train_data))\n",
        "print(\"Test-set size:  \", len(test_data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-set size:  25000\n",
            "Test-set size:   25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0_MzKDJjC9-"
      },
      "source": [
        "### Data 출력\n",
        "* 데이터셋을 바로 불러왔을때 출력되는 데이터를 확인해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkWxsmedjC9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd51bef4-fe6c-4813-fae4-9e06030977de"
      },
      "source": [
        "print(train_data[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxOl00BUjC-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b929c3-8d7f-41de-b69e-03b36eb5c6de"
      },
      "source": [
        "print(\"sequence length: {}\".format(len(train_data[1])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence length: 189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtrDXZZ3jC-F"
      },
      "source": [
        "* Label정보를 확인해보자\n",
        "  * 0.0 for a negative sentiment 부정적인 리뷰\n",
        "  * 1.0 for a positive sentiment 긍정적인 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:51.490655Z",
          "start_time": "2019-03-04T06:05:51.486122Z"
        },
        "id": "pAQISHYVjC-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10506a24-e3a9-46d0-ad4f-5ffa448651ba"
      },
      "source": [
        "# negative sample\n",
        "index = 1\n",
        "print(\"text: {}\\n\".format(train_data[index]))\n",
        "print(\"label: {}\".format(train_labels[index]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
            "\n",
            "label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:52.735239Z",
          "start_time": "2019-03-04T06:05:52.731203Z"
        },
        "id": "aE-lF_gqjC-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3021c7a6-b79e-418c-daea-66f3b9453577"
      },
      "source": [
        "# positive sample\n",
        "index = 200\n",
        "print(\"text: {}\\n\".format(train_data[index]))\n",
        "print(\"label: {}\".format(train_labels[index]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: [1, 14, 9, 6, 227, 196, 241, 634, 891, 234, 21, 12, 69, 6, 6, 176, 7, 4, 804, 4658, 2999, 667, 11, 12, 11, 85, 715, 6, 176, 7, 1565, 8, 1108, 10, 10, 12, 16, 1844, 2, 33, 211, 21, 69, 49, 2009, 905, 388, 99, 2, 125, 34, 6, 2, 1274, 33, 4, 130, 7, 4, 22, 15, 16, 6424, 8, 650, 1069, 14, 22, 9, 44, 4609, 153, 154, 4, 318, 302, 1051, 23, 14, 22, 122, 6, 2093, 292, 10, 10, 723, 8721, 5, 2, 9728, 71, 1344, 1576, 156, 11, 68, 251, 5, 36, 92, 4363, 133, 199, 743, 976, 354, 4, 64, 439, 9, 3059, 17, 32, 4, 2, 26, 256, 34, 2, 5, 49, 7, 98, 40, 2345, 9844, 43, 92, 168, 147, 474, 40, 8, 67, 6, 796, 97, 7, 14, 20, 19, 32, 2188, 156, 24, 18, 6090, 1007, 21, 8, 331, 97, 4, 65, 168, 5, 481, 53, 3084]\n",
            "\n",
            "label: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqlZw3GNjC-Q"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "### Convert the integers back to words\n",
        "\n",
        "* 실제 우리가 다루고 있는 데이터가 진짜 리뷰데이터인지 확인해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUX_-fu3jC-Q"
      },
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "  return ' '.join([reverse_word_index.get(i, '?') for i in text])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index)"
      ],
      "metadata": {
        "id": "sWIHZFwGk2Xt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bf2c42-93ac-43fa-9096-28323d63fd37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88588"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQd9gEAqjC-S"
      },
      "source": [
        "#### Text data 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-ss_usJjC-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8cfd99-566a-4ab4-e487-b7b06cea5229"
      },
      "source": [
        "print(train_data[5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 2, 10, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZsvB20qjC-V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "66ee95f6-3ca3-475e-84d6-5733b657d75b"
      },
      "source": [
        "decode_review(train_data[5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> begins better than it ends funny that the russian submarine crew <UNK> all other actors it's like those scenes where documentary shots br br spoiler part the message <UNK> was contrary to the whole story it just does not <UNK> br br\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJyBVg01TM0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d870131-4eff-4878-c452-66218c827e9e"
      },
      "source": [
        "print(train_labels[5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8yYy2OPjC-a"
      },
      "source": [
        "### Padding and truncating data using pad sequences\n",
        "* 전부 길이가 다른 리뷰들의 길이를 통일해주자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb0_NqMZjC-a"
      },
      "source": [
        "from tensorflow.keras.utils import pad_sequences"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU6L4MjLjC-c"
      },
      "source": [
        "num_seq_length = np.array([len(tokens) for tokens in list(train_data) + list(test_data)])\n",
        "train_seq_length = np.array([len(tokens) for tokens in train_data], dtype=np.int32)\n",
        "test_seq_length = np.array([len(tokens) for tokens in test_data], dtype=np.int32)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPg8nfTvjC-f"
      },
      "source": [
        "max_seq_length = 256"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmIjHB2CAzMv"
      },
      "source": [
        "* Max length보다 작은 리뷰의 퍼센트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6OsdVicjC-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7507874-2b2f-4432-e29d-f0fb94c8dd9f"
      },
      "source": [
        "print(np.sum(num_seq_length < max_seq_length) / len(num_seq_length))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.70518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjzECbvIjC-k"
      },
      "source": [
        "* `max_seq_length`을 256으로 설정하면 전체 데이터 셋의 70%를 커버할 수 있다.\n",
        "* 30% 정도의 데이터가 256 단어가 넘는 문장으로 이루어져 있다.\n",
        "* 보통 미리 정한 `max_seq_length`를 넘어가는 문장의 데이터는 *truncate* 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mygycLN_jC-k"
      },
      "source": [
        "# padding 옵션은 두 가지가 있다.\n",
        "pad = 'pre'\n",
        "# pad = 'post'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:07:16.640655Z",
          "start_time": "2019-03-04T06:07:16.607400Z"
        },
        "id": "nyIeOTuujC-m"
      },
      "source": [
        "train_data_pad = pad_sequences(train_data,\n",
        "                               maxlen=max_seq_length,\n",
        "                               padding=pad,\n",
        "                               value=word_index[\"<PAD>\"])\n",
        "test_data_pad = pad_sequences(test_data,\n",
        "                              maxlen=max_seq_length,\n",
        "                              padding=pad,\n",
        "                              value=word_index[\"<PAD>\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quksHiyqjC-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05518529-0243-4518-920d-82643122c21c"
      },
      "source": [
        "print(train_data_pad.shape)\n",
        "print(test_data_pad.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 256)\n",
            "(25000, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6YYEc0bjC-q"
      },
      "source": [
        "#### Padding data 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:07:59.449979Z",
          "start_time": "2019-03-04T06:07:58.334795Z"
        },
        "id": "dCI9mcsVjC-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb92036-6787-445a-ddcc-1f08d2568af0"
      },
      "source": [
        "index = 0\n",
        "print(\"text: {}\\n\".format(decode_review(train_data[index])))\n",
        "print(\"token: {}\\n\".format(train_data[index]))\n",
        "print(\"pad: {}\".format(train_data_pad[index]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "\n",
            "token: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "\n",
            "pad: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    1   14   22   16\n",
            "   43  530  973 1622 1385   65  458 4468   66 3941    4  173   36  256\n",
            "    5   25  100   43  838  112   50  670    2    9   35  480  284    5\n",
            "  150    4  172  112  167    2  336  385   39    4  172 4536 1111   17\n",
            "  546   38   13  447    4  192   50   16    6  147 2025   19   14   22\n",
            "    4 1920 4613  469    4   22   71   87   12   16   43  530   38   76\n",
            "   15   13 1247    4   22   17  515   17   12   16  626   18    2    5\n",
            "   62  386   12    8  316    8  106    5    4 2223 5244   16  480   66\n",
            " 3785   33    4  130   12   16   38  619    5   25  124   51   36  135\n",
            "   48   25 1415   33    6   22   12  215   28   77   52    5   14  407\n",
            "   16   82    2    8    4  107  117 5952   15  256    4    2    7 3766\n",
            "    5  723   36   71   43  530  476   26  400  317   46    7    4    2\n",
            " 1029   13  104   88    4  381   15  297   98   32 2071   56   26  141\n",
            "    6  194 7486   18    4  226   22   21  134  476   26  480    5  144\n",
            "   30 5535   18   51   36   28  224   92   25  104    4  226   65   16\n",
            "   38 1334   88   12   16  283    5   16 4472  113  103   32   15   16\n",
            " 5345   19  178   32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU115TnojC-t"
      },
      "source": [
        "### Create a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:08:04.189086Z",
          "start_time": "2019-03-04T06:08:04.184027Z"
        },
        "id": "cG6qc-5njC-t"
      },
      "source": [
        "num_val_data = int(0.1 * len(train_data_pad))\n",
        "val_data_pad = train_data_pad[:num_val_data]\n",
        "train_data_pad_partial = train_data_pad[num_val_data:]\n",
        "\n",
        "val_labels = train_labels[:num_val_data]\n",
        "train_labels_partial = train_labels[num_val_data:]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CPqHeI9y7g2"
      },
      "source": [
        "### Dataset 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhh2SOcjC_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f18ed51-83d8-4845-a753-ddf4dcaec84e"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# for train\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_pad_partial, train_labels_partial))\n",
        "train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=batch_size)\n",
        "print(train_dataset)\n",
        "\n",
        "# for test\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data_pad, test_labels))\n",
        "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
        "print(test_dataset)\n",
        "\n",
        "# for valid\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_data_pad, val_labels))\n",
        "valid_dataset = valid_dataset.batch(batch_size=batch_size)\n",
        "print(valid_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>\n",
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>\n",
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cxcQnl2FtsOC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5KBM5sdjC-v"
      },
      "source": [
        "## Setup hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:08:34.724505Z",
          "start_time": "2019-03-04T06:08:34.720495Z"
        },
        "id": "P1fls3PEjC-w"
      },
      "source": [
        "# Set the hyperparameter set\n",
        "max_epochs = 5\n",
        "embedding_size = 256\n",
        "rnn_units = 1024\n",
        "vocab_size = 10000\n",
        "\n",
        "# the save point\n",
        "if use_colab:\n",
        "    checkpoint_dir ='./drive/My Drive/train_ckpt/sentimental/exp1'\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "else:\n",
        "    checkpoint_dir = 'sentimental/exp1'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMG2MOXUjC-y"
      },
      "source": [
        "## Build the model\n",
        "### Embedding layer\n",
        "\n",
        "* embedding-layer는 전체 vocabulary의 갯수(num_words)로 이루어진 index가 `embedding_size`의 *dense vector* 로 변환되는 과정이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:10:48.761441Z",
          "start_time": "2019-03-04T06:10:48.753644Z"
        },
        "id": "0li13tSGjC-1"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_size,\n",
        "                                batch_input_shape=[batch_size, None]))\n",
        "\n",
        "model.add(layers.GRU(units=rnn_units//4, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
        "model.add(layers.GRU(units=rnn_units//2, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
        "model.add(layers.GRU(units=rnn_units, return_sequences=False, stateful=True, recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "model.add(layers.Dense(1)) # 이진 분류! 0 or 1"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JC5OGALjC-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b00b45-443c-4e5d-b06c-0bd79ab47d6a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (32, None, 256)           2560000   \n",
            "                                                                 \n",
            " gru (GRU)                   (32, None, 512)           1182720   \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (32, None, 512)           1575936   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (32, 512)                 1575936   \n",
            "                                                                 \n",
            " dense (Dense)               (32, 1)                   513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6895105 (26.30 MB)\n",
            "Trainable params: 6895105 (26.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXObUdM6jC--"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:11:19.741901Z",
          "start_time": "2019-03-04T06:11:19.734665Z"
        },
        "id": "Q-KOk-3ujC_A"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cruLtRx2jC_C"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qFJhZl6_NI5"
      },
      "source": [
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor='val_loss',\n",
        "                                                 mode='auto',\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:11:57.988951Z",
          "start_time": "2019-03-04T06:11:29.719361Z"
        },
        "id": "waom7QxfjC_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc50d9b-e286-401d-cfe1-781f05a12112"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=max_epochs,\n",
        "                    validation_data=valid_dataset,\n",
        "                    steps_per_epoch=len(train_labels_partial) // batch_size ,\n",
        "                    validation_steps=len(val_labels) // batch_size ,\n",
        "                    callbacks=[cp_callback]\n",
        "                    )\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "703/703 [==============================] - ETA: 0s - loss: 0.6465 - accuracy: 0.5645\n",
            "Epoch 1: val_loss improved from inf to 0.51237, saving model to ./drive/My Drive/train_ckpt/sentimental/exp1\n",
            "703/703 [==============================] - 107s 139ms/step - loss: 0.6465 - accuracy: 0.5645 - val_loss: 0.5124 - val_accuracy: 0.7135\n",
            "Epoch 2/5\n",
            "703/703 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8023\n",
            "Epoch 2: val_loss improved from 0.51237 to 0.39112, saving model to ./drive/My Drive/train_ckpt/sentimental/exp1\n",
            "703/703 [==============================] - 82s 116ms/step - loss: 0.4140 - accuracy: 0.8023 - val_loss: 0.3911 - val_accuracy: 0.8193\n",
            "Epoch 3/5\n",
            "703/703 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.8546\n",
            "Epoch 3: val_loss improved from 0.39112 to 0.35762, saving model to ./drive/My Drive/train_ckpt/sentimental/exp1\n",
            "703/703 [==============================] - 80s 113ms/step - loss: 0.3269 - accuracy: 0.8546 - val_loss: 0.3576 - val_accuracy: 0.8462\n",
            "Epoch 4/5\n",
            "703/703 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.8759\n",
            "Epoch 4: val_loss improved from 0.35762 to 0.33803, saving model to ./drive/My Drive/train_ckpt/sentimental/exp1\n",
            "703/703 [==============================] - 76s 109ms/step - loss: 0.2843 - accuracy: 0.8759 - val_loss: 0.3380 - val_accuracy: 0.8442\n",
            "Epoch 5/5\n",
            "703/703 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.8982\n",
            "Epoch 5: val_loss improved from 0.33803 to 0.33288, saving model to ./drive/My Drive/train_ckpt/sentimental/exp1\n",
            "703/703 [==============================] - 76s 109ms/step - loss: 0.2476 - accuracy: 0.8982 - val_loss: 0.3329 - val_accuracy: 0.8586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VYoFVsVjC_G"
      },
      "source": [
        "## 모델 테스트\n",
        "* 테스트 데이터셋을 이용해 모델을 테스트해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jiIGyqUvpY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f272389e-a8b8-4291-8de3-11622a1475d0"
      },
      "source": [
        "model.load_weights(checkpoint_dir)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ef789013340>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T05:56:34.572611Z",
          "start_time": "2019-03-04T05:56:34.116Z"
        },
        "id": "K-Z7Lg-TjC_G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "77e798a1-7847-46b2-8582-0dc1baea821b"
      },
      "source": [
        "results = model.evaluate(test_dataset)\n",
        "# loss\n",
        "print(\"loss value: {:.3f}\".format(results[0]))\n",
        "# accuracy\n",
        "print(\"accuracy value: {:.3f}\".format(results[1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "780/782 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8478"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node CudnnRNN defined at (most recent call last):\n<stack traces unavailable>\nInvalid input_h shape: [1,32,512] [1,8,512]\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/gru/PartitionedCall]] [Op:__inference_test_function_10840]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-5eedf45bfcda>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss value: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy value: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node CudnnRNN defined at (most recent call last):\n<stack traces unavailable>\nInvalid input_h shape: [1,32,512] [1,8,512]\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/gru/PartitionedCall]] [Op:__inference_test_function_10840]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avXaOtHsjC_I"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}